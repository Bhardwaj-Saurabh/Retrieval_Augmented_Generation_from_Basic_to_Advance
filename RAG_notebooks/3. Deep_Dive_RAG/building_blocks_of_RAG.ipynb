{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a04654ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original text: 'Hello! How are you doing today?'\n",
      "\n",
      "Token IDs: [9906, 0, 2650, 527, 499, 3815, 3432, 30]\n",
      "Number of tokens: 8\n",
      "\n",
      "Decoding each token:\n",
      "  Token ID  9906 -> 'Hello'\n",
      "  Token ID     0 -> '!'\n",
      "  Token ID  2650 -> ' How'\n",
      "  Token ID   527 -> ' are'\n",
      "  Token ID   499 -> ' you'\n",
      "  Token ID  3815 -> ' doing'\n",
      "  Token ID  3432 -> ' today'\n",
      "  Token ID    30 -> '?'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 1. TOKENS AND TOKENIZATION\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "text = \"Hello! How are you doing today?\"\n",
    "\n",
    "# Load tokenizer\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")  # GPT-4 tokenizer\n",
    "\n",
    "# Tokenize\n",
    "tokens = encoding.encode(text)\n",
    "\n",
    "print(f\"\\nOriginal text: '{text}'\")\n",
    "print(f\"\\nToken IDs: {tokens}\")\n",
    "print(f\"Number of tokens: {len(tokens)}\")\n",
    "\n",
    "# Decode back to text\n",
    "print(\"\\nDecoding each token:\")\n",
    "for token_id in tokens:\n",
    "    token_text = encoding.decode([token_id])\n",
    "    print(f\"  Token ID {token_id:5d} -> '{token_text}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c6c3d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saurabhbhardwaj/Desktop/Retrieval_Augmented_Generation_from_Basic_to_Advance/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated embeddings for 3 sentences\n",
      "Embedding dimensions: 384\n",
      "\n",
      "Sentence 1: 'The cat sits on the mat'\n",
      "Embedding (first 10 values): [ 0.13489066 -0.03206333 -0.02033523  0.03590099 -0.0283331   0.04150213\n",
      "  0.03315875  0.03660566  0.00861661  0.03763952]\n",
      "Embedding (last 10 values): [-0.08110048 -0.04863552  0.01041568  0.00716836  0.03275092  0.05027731\n",
      "  0.00980353  0.04674229  0.01492449  0.05863348]\n",
      "\n",
      "Sentence 2: 'A feline rests on the rug'\n",
      "Embedding (first 10 values): [ 0.06828602  0.02979378  0.03781996  0.11503891 -0.02664034  0.07539926\n",
      "  0.01991902  0.00916963  0.01979519  0.02939497]\n",
      "Embedding (last 10 values): [-0.02178581 -0.02646917 -0.00078678 -0.01127525  0.08196999  0.09736849\n",
      "  0.04664826 -0.00084484  0.01191917  0.03106434]\n",
      "\n",
      "Sentence 3: 'The dog runs in the park'\n",
      "Embedding (first 10 values): [ 0.05794052 -0.03488497  0.05711472 -0.00158803  0.05946509 -0.02963705\n",
      " -0.01222521  0.01785607  0.06413977  0.03801326]\n",
      "Embedding (last 10 values): [ 0.02910725  0.02868083 -0.06278066 -0.02812437 -0.02644941  0.01573016\n",
      " -0.07190384  0.04697108  0.04663432  0.01261119]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 2. EMBEDDINGS\n",
    "# ============================================================================\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a small, fast model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Example sentences\n",
    "sentences = [\n",
    "    \"The cat sits on the mat\",\n",
    "    \"A feline rests on the rug\",\n",
    "    \"The dog runs in the park\"\n",
    "]\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "print(f\"\\nGenerated embeddings for {len(sentences)} sentences\")\n",
    "print(f\"Embedding dimensions: {embeddings[0].shape[0]}\")\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    print(f\"\\nSentence {i+1}: '{sentence}'\")\n",
    "    print(f\"Embedding (first 10 values): {embeddings[i][:10]}\")\n",
    "    print(f\"Embedding (last 10 values): {embeddings[i][-10:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c8db81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing sentence similarities:\n",
      "\n",
      "Sentence 1: 'The cat sits on the mat'\n",
      "Sentence 2: 'A feline rests on the rug'\n",
      "Sentence 3: 'The dog runs in the park'\n",
      "\n",
      "Similarity (Sentence 1 ↔ Sentence 2): 0.5607\n",
      "Similarity (Sentence 1 ↔ Sentence 3): 0.0949\n",
      "Similarity (Sentence 2 ↔ Sentence 3): 0.0973\n",
      "\n",
      "Interpretation:\n",
      "- Sentences 1 & 2 should be MOST similar (same meaning, different words)\n",
      "- Sentences 1 & 3 should be LEAST similar (different meanings)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 3. VECTOR SIMILARITY (Cosine Similarity)\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Calculate cosine similarity between two vectors\"\"\"\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    \n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "# Using embeddings from previous step\n",
    "if 'embeddings' in locals() and len(embeddings) >= 3:\n",
    "    print(\"\\nComparing sentence similarities:\")\n",
    "    print(f\"\\nSentence 1: '{sentences[0]}'\")\n",
    "    print(f\"Sentence 2: '{sentences[1]}'\")\n",
    "    print(f\"Sentence 3: '{sentences[2]}'\")\n",
    "    \n",
    "    # Calculate similarities\n",
    "    sim_1_2 = cosine_similarity(embeddings[0], embeddings[1])\n",
    "    sim_1_3 = cosine_similarity(embeddings[0], embeddings[2])\n",
    "    sim_2_3 = cosine_similarity(embeddings[1], embeddings[2])\n",
    "    \n",
    "    print(f\"\\nSimilarity (Sentence 1 ↔ Sentence 2): {sim_1_2:.4f}\")\n",
    "    print(f\"Similarity (Sentence 1 ↔ Sentence 3): {sim_1_3:.4f}\")\n",
    "    print(f\"Similarity (Sentence 2 ↔ Sentence 3): {sim_2_3:.4f}\")\n",
    "    \n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"- Sentences 1 & 2 should be MOST similar (same meaning, different words)\")\n",
    "    print(\"- Sentences 1 & 3 should be LEAST similar (different meanings)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfb53d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: 'What is deep learning?'\n",
      "\n",
      "Searching through 5 documents...\n",
      "\n",
      "Results (ranked by relevance):\n",
      "\n",
      "1. [Score: 0.7540] Deep learning is a subset of machine learning\n",
      "\n",
      "2. [Score: 0.4643] Machine learning uses algorithms to learn from data\n",
      "\n",
      "3. [Score: 0.2547] JavaScript is used for web development\n",
      "\n",
      "4. [Score: 0.2431] Python is a programming language\n",
      "\n",
      "5. [Score: -0.0161] The Eiffel Tower is in Paris\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 4. VECTOR SEARCH (Finding Most Similar Document)\n",
    "# ============================================================================\n",
    "\n",
    "# Simulate a simple vector search\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Our \"knowledge base\" of documents\n",
    "documents = [\n",
    "    \"Python is a programming language\",\n",
    "    \"Machine learning uses algorithms to learn from data\",\n",
    "    \"The Eiffel Tower is in Paris\",\n",
    "    \"Deep learning is a subset of machine learning\",\n",
    "    \"JavaScript is used for web development\"\n",
    "]\n",
    "\n",
    "# Embed all documents\n",
    "doc_embeddings = model.encode(documents)\n",
    "\n",
    "# User query\n",
    "query = \"What is deep learning?\"\n",
    "query_embedding = model.encode([query])[0]\n",
    "\n",
    "print(f\"\\nQuery: '{query}'\")\n",
    "print(f\"\\nSearching through {len(documents)} documents...\\n\")\n",
    "\n",
    "# Calculate similarity with each document\n",
    "similarities = []\n",
    "for i, doc_emb in enumerate(doc_embeddings):\n",
    "    similarity = cosine_similarity(query_embedding, doc_emb)\n",
    "    similarities.append((i, similarity))\n",
    "\n",
    "# Sort by similarity (highest first)\n",
    "similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Results (ranked by relevance):\")\n",
    "for rank, (doc_idx, score) in enumerate(similarities, 1):\n",
    "    print(f\"\\n{rank}. [Score: {score:.4f}] {documents[doc_idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b30f668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saurabhbhardwaj/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:16<00:00, 4.96MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Added 5 documents to vector database\n",
      "\n",
      "Query: 'Tell me about artificial intelligence'\n",
      "\n",
      "Searching vector database...\n",
      "\n",
      "Top 3 Results:\n",
      "\n",
      "1. [Distance: 1.0995]\n",
      "   Document: Neural networks are inspired by the brain\n",
      "   Source: document_3.txt\n",
      "\n",
      "2. [Distance: 1.1080]\n",
      "   Document: Machine learning enables computers to learn\n",
      "   Source: document_1.txt\n",
      "\n",
      "3. [Distance: 1.3073]\n",
      "   Document: Python is a high-level programming language\n",
      "   Source: document_0.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 5. VECTOR DATABASE (Chromadb - Simple Example)\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# Create a simple in-memory database\n",
    "client = chromadb.Client()\n",
    "\n",
    "# Create or get collection\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"my_documents\",\n",
    "    embedding_function=embedding_functions.DefaultEmbeddingFunction()\n",
    ")\n",
    "\n",
    "# Add documents to the database\n",
    "documents = [\n",
    "    \"Python is a high-level programming language\",\n",
    "    \"Machine learning enables computers to learn\",\n",
    "    \"Paris is the capital of France\",\n",
    "    \"Neural networks are inspired by the brain\",\n",
    "    \"JavaScript runs in web browsers\"\n",
    "]\n",
    "\n",
    "# Add documents with IDs and metadata\n",
    "collection.add(\n",
    "    documents=documents,\n",
    "    ids=[f\"doc_{i}\" for i in range(len(documents))],\n",
    "    metadatas=[{\"source\": f\"document_{i}.txt\"} for i in range(len(documents))]\n",
    ")\n",
    "\n",
    "print(f\"\\nAdded {len(documents)} documents to vector database\")\n",
    "\n",
    "# Query the database\n",
    "query = \"Tell me about artificial intelligence\"\n",
    "\n",
    "print(f\"\\nQuery: '{query}'\")\n",
    "print(\"\\nSearching vector database...\\n\")\n",
    "\n",
    "results = collection.query(\n",
    "    query_texts=[query],\n",
    "    n_results=3  # Return top 3 results\n",
    ")\n",
    "\n",
    "print(\"Top 3 Results:\")\n",
    "for i, (doc, distance, metadata) in enumerate(zip(\n",
    "    results['documents'][0],\n",
    "    results['distances'][0],\n",
    "    results['metadatas'][0]\n",
    "), 1):\n",
    "    print(f\"\\n{i}. [Distance: {distance:.4f}]\")\n",
    "    print(f\"   Document: {doc}\")\n",
    "    print(f\"   Source: {metadata['source']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ee0e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47246de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd21fd57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ecf038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Retrieval_Augmented_Generation_from_Basic_to_Advance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
